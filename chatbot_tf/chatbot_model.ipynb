{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "    print(df.head())\n",
    "    intent = df[\"Intent\"]\n",
    "    unique_intent = list(set(intent))\n",
    "    sentences = list(df[\"Sentence\"])\n",
    "    return (intent, unique_intent, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Sentence  Intent\n",
      "0  Is there a bot chatting to me?  GQ.bot\n",
      "1        Is it automated message?  GQ.bot\n",
      "2             Computer based pely  GQ.bot\n",
      "3                   Bot or human?  GQ.bot\n",
      "4        Bot is chatting with me?  GQ.bot\n"
     ]
    }
   ],
   "source": [
    "intent, unique_intent, sentences = load_dataset(\"opencon_dataset_augmented2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What's the club about?\", 'What does IEEE-VIT does', 'What is IEEE-VIT?', 'What is ieee', 'What is IEEE vit ?']\n",
      "['SQ.reg_fee', 'GQ.gen', 'FAQ.accom', 'SQ.event_date', 'SQ.event_details', 'GQ.query', 'SQ.event_prize', 'GQ.help', 'FAQ.contact_info', 'FAQ.why_reg', 'SQ.event_speakers', 'JOIN.sponsor', 'JOIN.speaker', 'SQ.reg_lastdate', 'SQ.event_schedule', 'FAQ.food', 'GQ.bot', 'GQ.name', 'SQ.IEEE']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[100:105])\n",
    "print(unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()  #using lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "        w = word_tokenize(clean)\n",
    "        #stemming\n",
    "        words.append([i.lower() for i in w])\n",
    "    \n",
    "    return words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3626\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'the', 'registration', 'fee', 'of', 'the', 'event'], ['what', 'is', 'the', 'fees', 'required', 'to', 'register', 'for', 'the', 'event'], ['what', 's', 'the', 'price', 'for', 'getting', 'a', 'registration', 'done', 'in', 'the', 'event']]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_words[115:118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "    token = Tokenizer(filters = filters)\n",
    "    token.fit_on_texts(words)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "    return(len(max(words, key = len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 1384 and Maximum length = 27\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "    return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,   3,   1,  31, 124,  22,   1,   5,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [  2,   3,   1, 108, 189,   7,  25,   6,   1,   5,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [  2,  50,   1, 236,   6, 225,  12,  31, 168,  24,   1,   5,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[115:118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (3626, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sq.reg_fee': 1,\n",
       " 'gq.gen': 2,\n",
       " 'faq.accom': 3,\n",
       " 'sq.event_date': 4,\n",
       " 'sq.event_details': 5,\n",
       " 'gq.query': 6,\n",
       " 'sq.event_prize': 7,\n",
       " 'gq.help': 8,\n",
       " 'faq.contact_info': 9,\n",
       " 'faq.why_reg': 10,\n",
       " 'sq.event_speakers': 11,\n",
       " 'join.sponsor': 12,\n",
       " 'join.speaker': 13,\n",
       " 'sq.reg_lastdate': 14,\n",
       " 'sq.event_schedule': 15,\n",
       " 'faq.food': 16,\n",
       " 'gq.bot': 17,\n",
       " 'gq.name': 18,\n",
       " 'sq.ieee': 19}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3626, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "    o = OneHotEncoder(sparse = False)\n",
    "    return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3626, 19)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.25)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(padded_doc, output_one_hot, test_size = 0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (2719, 27) and train_Y = (2719, 19)\n",
      "Shape of val_X = (907, 27) and val_Y = (907, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (x_train.shape, y_train.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation = \"relu\"))    ###\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(19, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "##may need to define custom optimizer (adam) with low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2719 samples, validate on 907 samples\n",
      "Epoch 1/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 2.9015 - accuracy: 0.0687\n",
      "Epoch 00001: val_loss improved from inf to 2.80859, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 5s 2ms/sample - loss: 2.8986 - accuracy: 0.0713 - val_loss: 2.8086 - val_accuracy: 0.1047\n",
      "Epoch 2/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 2.6622 - accuracy: 0.1581\n",
      "Epoch 00002: val_loss improved from 2.80859 to 2.40900, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 450us/sample - loss: 2.6475 - accuracy: 0.1592 - val_loss: 2.4090 - val_accuracy: 0.2624\n",
      "Epoch 3/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 2.2342 - accuracy: 0.2911\n",
      "Epoch 00003: val_loss improved from 2.40900 to 1.99832, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 445us/sample - loss: 2.2291 - accuracy: 0.2913 - val_loss: 1.9983 - val_accuracy: 0.4267\n",
      "Epoch 4/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 1.8701 - accuracy: 0.3996\n",
      "Epoch 00004: val_loss improved from 1.99832 to 1.63091, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 478us/sample - loss: 1.8704 - accuracy: 0.4009 - val_loss: 1.6309 - val_accuracy: 0.5237\n",
      "Epoch 5/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 1.5898 - accuracy: 0.4941\n",
      "Epoch 00005: val_loss improved from 1.63091 to 1.40756, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 454us/sample - loss: 1.5881 - accuracy: 0.4943 - val_loss: 1.4076 - val_accuracy: 0.5943\n",
      "Epoch 6/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 1.3715 - accuracy: 0.5541\n",
      "Epoch 00006: val_loss improved from 1.40756 to 1.15575, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 468us/sample - loss: 1.3756 - accuracy: 0.5517 - val_loss: 1.1558 - val_accuracy: 0.6483\n",
      "Epoch 7/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 1.2050 - accuracy: 0.6105\n",
      "Epoch 00007: val_loss improved from 1.15575 to 1.07159, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 477us/sample - loss: 1.2044 - accuracy: 0.6094 - val_loss: 1.0716 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 1.0798 - accuracy: 0.6615\n",
      "Epoch 00008: val_loss improved from 1.07159 to 0.87534, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 468us/sample - loss: 1.0684 - accuracy: 0.6657 - val_loss: 0.8753 - val_accuracy: 0.7453\n",
      "Epoch 9/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.9477 - accuracy: 0.7000\n",
      "Epoch 00009: val_loss improved from 0.87534 to 0.85027, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 458us/sample - loss: 0.9472 - accuracy: 0.7006 - val_loss: 0.8503 - val_accuracy: 0.7508\n",
      "Epoch 10/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.8448 - accuracy: 0.7362\n",
      "Epoch 00010: val_loss did not improve from 0.85027\n",
      "2719/2719 [==============================] - 1s 444us/sample - loss: 0.8476 - accuracy: 0.7367 - val_loss: 1.0103 - val_accuracy: 0.7266\n",
      "Epoch 11/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.7909 - accuracy: 0.7530\n",
      "Epoch 00011: val_loss improved from 0.85027 to 0.63147, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 451us/sample - loss: 0.7886 - accuracy: 0.7540 - val_loss: 0.6315 - val_accuracy: 0.8247\n",
      "Epoch 12/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.6555 - accuracy: 0.7881\n",
      "Epoch 00012: val_loss did not improve from 0.63147\n",
      "2719/2719 [==============================] - 1s 427us/sample - loss: 0.6551 - accuracy: 0.7882 - val_loss: 0.6591 - val_accuracy: 0.8236\n",
      "Epoch 13/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.7928\n",
      "Epoch 00013: val_loss improved from 0.63147 to 0.62999, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 440us/sample - loss: 0.6666 - accuracy: 0.7918 - val_loss: 0.6300 - val_accuracy: 0.8082\n",
      "Epoch 14/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.5751 - accuracy: 0.8284\n",
      "Epoch 00014: val_loss improved from 0.62999 to 0.56359, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 438us/sample - loss: 0.5768 - accuracy: 0.8275 - val_loss: 0.5636 - val_accuracy: 0.8324\n",
      "Epoch 15/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.5011 - accuracy: 0.8412\n",
      "Epoch 00015: val_loss improved from 0.56359 to 0.42874, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 450us/sample - loss: 0.5004 - accuracy: 0.8415 - val_loss: 0.4287 - val_accuracy: 0.8831\n",
      "Epoch 16/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.4636 - accuracy: 0.8623\n",
      "Epoch 00016: val_loss did not improve from 0.42874\n",
      "2719/2719 [==============================] - 1s 456us/sample - loss: 0.4609 - accuracy: 0.8628 - val_loss: 0.4486 - val_accuracy: 0.8765\n",
      "Epoch 17/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.4185 - accuracy: 0.8725\n",
      "Epoch 00017: val_loss did not improve from 0.42874\n",
      "2719/2719 [==============================] - 1s 434us/sample - loss: 0.4186 - accuracy: 0.8727 - val_loss: 0.4389 - val_accuracy: 0.8787\n",
      "Epoch 18/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.4120 - accuracy: 0.8698\n",
      "Epoch 00018: val_loss improved from 0.42874 to 0.38494, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 455us/sample - loss: 0.4172 - accuracy: 0.8683 - val_loss: 0.3849 - val_accuracy: 0.8986\n",
      "Epoch 19/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.3852 - accuracy: 0.8865\n",
      "Epoch 00019: val_loss did not improve from 0.38494\n",
      "2719/2719 [==============================] - 1s 483us/sample - loss: 0.3869 - accuracy: 0.8853 - val_loss: 0.4210 - val_accuracy: 0.8931\n",
      "Epoch 20/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.3548 - accuracy: 0.8942\n",
      "Epoch 00020: val_loss improved from 0.38494 to 0.33802, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 434us/sample - loss: 0.3543 - accuracy: 0.8944 - val_loss: 0.3380 - val_accuracy: 0.9008\n",
      "Epoch 21/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8937\n",
      "Epoch 00021: val_loss did not improve from 0.33802\n",
      "2719/2719 [==============================] - 1s 473us/sample - loss: 0.3503 - accuracy: 0.8933 - val_loss: 0.3521 - val_accuracy: 0.9008\n",
      "Epoch 22/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.3972 - accuracy: 0.8838\n",
      "Epoch 00022: val_loss did not improve from 0.33802\n",
      "2719/2719 [==============================] - 1s 465us/sample - loss: 0.3922 - accuracy: 0.8856 - val_loss: 0.3973 - val_accuracy: 0.8908\n",
      "Epoch 23/100\n",
      "2560/2719 [===========================>..] - ETA: 0s - loss: 0.2965 - accuracy: 0.9191\n",
      "Epoch 00023: val_loss improved from 0.33802 to 0.32036, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 455us/sample - loss: 0.2978 - accuracy: 0.9180 - val_loss: 0.3204 - val_accuracy: 0.9107\n",
      "Epoch 24/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.2475 - accuracy: 0.9244\n",
      "Epoch 00024: val_loss improved from 0.32036 to 0.26801, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 443us/sample - loss: 0.2457 - accuracy: 0.9253 - val_loss: 0.2680 - val_accuracy: 0.9261\n",
      "Epoch 25/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.2136 - accuracy: 0.9319\n",
      "Epoch 00025: val_loss did not improve from 0.26801\n",
      "2719/2719 [==============================] - 1s 481us/sample - loss: 0.2131 - accuracy: 0.9316 - val_loss: 0.3204 - val_accuracy: 0.9173\n",
      "Epoch 26/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.2381 - accuracy: 0.9315\n",
      "Epoch 00026: val_loss did not improve from 0.26801\n",
      "2719/2719 [==============================] - 1s 475us/sample - loss: 0.2361 - accuracy: 0.9323 - val_loss: 0.3486 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.9068\n",
      "Epoch 00027: val_loss did not improve from 0.26801\n",
      "2719/2719 [==============================] - 1s 469us/sample - loss: 0.3147 - accuracy: 0.9077 - val_loss: 0.4944 - val_accuracy: 0.8754\n",
      "Epoch 28/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9429\n",
      "Epoch 00028: val_loss improved from 0.26801 to 0.24207, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 466us/sample - loss: 0.2113 - accuracy: 0.9430 - val_loss: 0.2421 - val_accuracy: 0.9305\n",
      "Epoch 29/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1681 - accuracy: 0.9519\n",
      "Epoch 00029: val_loss improved from 0.24207 to 0.23525, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 442us/sample - loss: 0.1667 - accuracy: 0.9533 - val_loss: 0.2353 - val_accuracy: 0.9394\n",
      "Epoch 30/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1919 - accuracy: 0.9473\n",
      "Epoch 00030: val_loss did not improve from 0.23525\n",
      "2719/2719 [==============================] - 1s 444us/sample - loss: 0.1917 - accuracy: 0.9489 - val_loss: 0.3138 - val_accuracy: 0.9173\n",
      "Epoch 31/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.2905 - accuracy: 0.9191\n",
      "Epoch 00031: val_loss did not improve from 0.23525\n",
      "2719/2719 [==============================] - 1s 484us/sample - loss: 0.2866 - accuracy: 0.9187 - val_loss: 0.2679 - val_accuracy: 0.9283\n",
      "Epoch 32/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1802 - accuracy: 0.9447\n",
      "Epoch 00032: val_loss did not improve from 0.23525\n",
      "2719/2719 [==============================] - 1s 473us/sample - loss: 0.1797 - accuracy: 0.9448 - val_loss: 0.2417 - val_accuracy: 0.9350\n",
      "Epoch 33/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.1425 - accuracy: 0.9592\n",
      "Epoch 00033: val_loss did not improve from 0.23525\n",
      "2719/2719 [==============================] - 1s 468us/sample - loss: 0.1408 - accuracy: 0.9592 - val_loss: 0.2367 - val_accuracy: 0.9405\n",
      "Epoch 34/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1169 - accuracy: 0.9660\n",
      "Epoch 00034: val_loss improved from 0.23525 to 0.19744, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 501us/sample - loss: 0.1166 - accuracy: 0.9658 - val_loss: 0.1974 - val_accuracy: 0.9427\n",
      "Epoch 35/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9663\n",
      "Epoch 00035: val_loss did not improve from 0.19744\n",
      "2719/2719 [==============================] - 1s 476us/sample - loss: 0.1180 - accuracy: 0.9662 - val_loss: 0.2650 - val_accuracy: 0.9449\n",
      "Epoch 36/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9469\n",
      "Epoch 00036: val_loss did not improve from 0.19744\n",
      "2719/2719 [==============================] - 1s 469us/sample - loss: 0.1891 - accuracy: 0.9481 - val_loss: 0.2916 - val_accuracy: 0.9272\n",
      "Epoch 37/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9613\n",
      "Epoch 00037: val_loss did not improve from 0.19744\n",
      "2719/2719 [==============================] - 1s 454us/sample - loss: 0.1275 - accuracy: 0.9614 - val_loss: 0.2024 - val_accuracy: 0.9416\n",
      "Epoch 38/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9728\n",
      "Epoch 00038: val_loss improved from 0.19744 to 0.18959, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 483us/sample - loss: 0.1001 - accuracy: 0.9732 - val_loss: 0.1896 - val_accuracy: 0.9482\n",
      "Epoch 39/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9773\n",
      "Epoch 00039: val_loss did not improve from 0.18959\n",
      "2719/2719 [==============================] - 1s 462us/sample - loss: 0.0944 - accuracy: 0.9772 - val_loss: 0.2198 - val_accuracy: 0.9548\n",
      "Epoch 40/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.1374 - accuracy: 0.9659\n",
      "Epoch 00040: val_loss did not improve from 0.18959\n",
      "2719/2719 [==============================] - 1s 420us/sample - loss: 0.1351 - accuracy: 0.9665 - val_loss: 0.2090 - val_accuracy: 0.9438\n",
      "Epoch 41/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9814\n",
      "Epoch 00041: val_loss did not improve from 0.18959\n",
      "2719/2719 [==============================] - 1s 411us/sample - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.2152 - val_accuracy: 0.9449\n",
      "Epoch 42/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.9695\n",
      "Epoch 00042: val_loss did not improve from 0.18959\n",
      "2719/2719 [==============================] - 1s 428us/sample - loss: 0.1119 - accuracy: 0.9695 - val_loss: 0.2114 - val_accuracy: 0.9438\n",
      "Epoch 43/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9741\n",
      "Epoch 00043: val_loss improved from 0.18959 to 0.18646, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 491us/sample - loss: 0.0957 - accuracy: 0.9743 - val_loss: 0.1865 - val_accuracy: 0.9482\n",
      "Epoch 44/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1858 - accuracy: 0.9573\n",
      "Epoch 00044: val_loss improved from 0.18646 to 0.15604, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 488us/sample - loss: 0.1830 - accuracy: 0.9577 - val_loss: 0.1560 - val_accuracy: 0.9603\n",
      "Epoch 45/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9812\n",
      "Epoch 00045: val_loss did not improve from 0.15604\n",
      "2719/2719 [==============================] - 1s 490us/sample - loss: 0.0662 - accuracy: 0.9812 - val_loss: 0.1770 - val_accuracy: 0.9548\n",
      "Epoch 46/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0914 - accuracy: 0.9756\n",
      "Epoch 00046: val_loss did not improve from 0.15604\n",
      "2719/2719 [==============================] - 1s 446us/sample - loss: 0.0908 - accuracy: 0.9757 - val_loss: 0.1859 - val_accuracy: 0.9537\n",
      "Epoch 47/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9785\n",
      "Epoch 00047: val_loss improved from 0.15604 to 0.15523, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 460us/sample - loss: 0.0962 - accuracy: 0.9783 - val_loss: 0.1552 - val_accuracy: 0.9526\n",
      "Epoch 48/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9838\n",
      "Epoch 00048: val_loss did not improve from 0.15523\n",
      "2719/2719 [==============================] - 1s 428us/sample - loss: 0.0637 - accuracy: 0.9838 - val_loss: 0.2166 - val_accuracy: 0.9548\n",
      "Epoch 49/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9793\n",
      "Epoch 00049: val_loss improved from 0.15523 to 0.15232, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 449us/sample - loss: 0.0774 - accuracy: 0.9790 - val_loss: 0.1523 - val_accuracy: 0.9548\n",
      "Epoch 50/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0967 - accuracy: 0.9736\n",
      "Epoch 00050: val_loss did not improve from 0.15232\n",
      "2719/2719 [==============================] - 1s 448us/sample - loss: 0.0964 - accuracy: 0.9743 - val_loss: 0.2036 - val_accuracy: 0.9526\n",
      "Epoch 51/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.1024 - accuracy: 0.9729\n",
      "Epoch 00051: val_loss did not improve from 0.15232\n",
      "2719/2719 [==============================] - 1s 440us/sample - loss: 0.1000 - accuracy: 0.9739 - val_loss: 0.1700 - val_accuracy: 0.9559\n",
      "Epoch 52/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.0700 - accuracy: 0.9808\n",
      "Epoch 00052: val_loss improved from 0.15232 to 0.14814, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 475us/sample - loss: 0.0680 - accuracy: 0.9816 - val_loss: 0.1481 - val_accuracy: 0.9636\n",
      "Epoch 53/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9872\n",
      "Epoch 00053: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 448us/sample - loss: 0.0519 - accuracy: 0.9868 - val_loss: 0.1998 - val_accuracy: 0.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9803\n",
      "Epoch 00054: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 438us/sample - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.1953 - val_accuracy: 0.9515\n",
      "Epoch 55/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9709\n",
      "Epoch 00055: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 449us/sample - loss: 0.1101 - accuracy: 0.9717 - val_loss: 0.2121 - val_accuracy: 0.9548\n",
      "Epoch 56/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0527 - accuracy: 0.9863\n",
      "Epoch 00056: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 459us/sample - loss: 0.0520 - accuracy: 0.9868 - val_loss: 0.2206 - val_accuracy: 0.9570\n",
      "Epoch 57/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0632 - accuracy: 0.9874\n",
      "Epoch 00057: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 466us/sample - loss: 0.0621 - accuracy: 0.9879 - val_loss: 0.1502 - val_accuracy: 0.9702\n",
      "Epoch 58/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0578 - accuracy: 0.9836\n",
      "Epoch 00058: val_loss did not improve from 0.14814\n",
      "2719/2719 [==============================] - 1s 441us/sample - loss: 0.0566 - accuracy: 0.9842 - val_loss: 0.2135 - val_accuracy: 0.9559\n",
      "Epoch 59/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0855 - accuracy: 0.9821\n",
      "Epoch 00059: val_loss improved from 0.14814 to 0.13062, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 502us/sample - loss: 0.0851 - accuracy: 0.9820 - val_loss: 0.1306 - val_accuracy: 0.9691\n",
      "Epoch 60/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9750\n",
      "Epoch 00060: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 469us/sample - loss: 0.0969 - accuracy: 0.9746 - val_loss: 0.1965 - val_accuracy: 0.9559\n",
      "Epoch 61/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9835\n",
      "Epoch 00061: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 457us/sample - loss: 0.0691 - accuracy: 0.9838 - val_loss: 0.1879 - val_accuracy: 0.9570\n",
      "Epoch 62/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9880\n",
      "Epoch 00062: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 455us/sample - loss: 0.0515 - accuracy: 0.9879 - val_loss: 0.3138 - val_accuracy: 0.9482\n",
      "Epoch 63/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9818\n",
      "Epoch 00063: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 462us/sample - loss: 0.0745 - accuracy: 0.9809 - val_loss: 0.1641 - val_accuracy: 0.9636\n",
      "Epoch 64/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9900\n",
      "Epoch 00064: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 443us/sample - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.1494 - val_accuracy: 0.9614\n",
      "Epoch 65/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.0375 - accuracy: 0.9915\n",
      "Epoch 00065: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 439us/sample - loss: 0.0381 - accuracy: 0.9915 - val_loss: 0.1334 - val_accuracy: 0.9647\n",
      "Epoch 66/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9937\n",
      "Epoch 00066: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 405us/sample - loss: 0.0270 - accuracy: 0.9934 - val_loss: 0.1921 - val_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9448\n",
      "Epoch 00067: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 419us/sample - loss: 0.2336 - accuracy: 0.9445 - val_loss: 0.2488 - val_accuracy: 0.9272\n",
      "Epoch 68/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.1033 - accuracy: 0.9737\n",
      "Epoch 00068: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 436us/sample - loss: 0.1042 - accuracy: 0.9735 - val_loss: 0.1597 - val_accuracy: 0.9581\n",
      "Epoch 69/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0417 - accuracy: 0.9899\n",
      "Epoch 00069: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 441us/sample - loss: 0.0420 - accuracy: 0.9901 - val_loss: 0.1746 - val_accuracy: 0.9515\n",
      "Epoch 70/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0471 - accuracy: 0.9880\n",
      "Epoch 00070: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 402us/sample - loss: 0.0472 - accuracy: 0.9875 - val_loss: 0.1578 - val_accuracy: 0.9625\n",
      "Epoch 71/100\n",
      "2560/2719 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9926\n",
      "Epoch 00071: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 447us/sample - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.1361 - val_accuracy: 0.9680\n",
      "Epoch 72/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 00072: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 440us/sample - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.1451 - val_accuracy: 0.9603\n",
      "Epoch 73/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9948\n",
      "Epoch 00073: val_loss did not improve from 0.13062\n",
      "2719/2719 [==============================] - 1s 414us/sample - loss: 0.0259 - accuracy: 0.9949 - val_loss: 0.1505 - val_accuracy: 0.9636\n",
      "Epoch 74/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0302 - accuracy: 0.9907\n",
      "Epoch 00074: val_loss improved from 0.13062 to 0.10181, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 457us/sample - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.1018 - val_accuracy: 0.9735\n",
      "Epoch 75/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9955\n",
      "Epoch 00075: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 449us/sample - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.1198 - val_accuracy: 0.9691\n",
      "Epoch 76/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0190 - accuracy: 0.9973\n",
      "Epoch 00076: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 443us/sample - loss: 0.0192 - accuracy: 0.9971 - val_loss: 0.1357 - val_accuracy: 0.9691\n",
      "Epoch 77/100\n",
      "2560/2719 [===========================>..] - ETA: 0s - loss: 0.0239 - accuracy: 0.9941\n",
      "Epoch 00077: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 420us/sample - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.2052 - val_accuracy: 0.9592\n",
      "Epoch 78/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9905\n",
      "Epoch 00078: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 415us/sample - loss: 0.0461 - accuracy: 0.9908 - val_loss: 0.1529 - val_accuracy: 0.9680\n",
      "Epoch 79/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0682 - accuracy: 0.9824\n",
      "Epoch 00079: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 441us/sample - loss: 0.0704 - accuracy: 0.9816 - val_loss: 0.1991 - val_accuracy: 0.9449\n",
      "Epoch 80/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.9670\n",
      "Epoch 00080: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 414us/sample - loss: 0.1340 - accuracy: 0.9669 - val_loss: 0.2430 - val_accuracy: 0.9316\n",
      "Epoch 81/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9787\n",
      "Epoch 00081: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 429us/sample - loss: 0.0887 - accuracy: 0.9790 - val_loss: 0.1020 - val_accuracy: 0.9713\n",
      "Epoch 82/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9918\n",
      "Epoch 00082: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 429us/sample - loss: 0.0305 - accuracy: 0.9919 - val_loss: 0.1251 - val_accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9931\n",
      "Epoch 00083: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 437us/sample - loss: 0.0286 - accuracy: 0.9934 - val_loss: 0.1168 - val_accuracy: 0.9713\n",
      "Epoch 84/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9902\n",
      "Epoch 00084: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 412us/sample - loss: 0.0421 - accuracy: 0.9904 - val_loss: 0.1486 - val_accuracy: 0.9636\n",
      "Epoch 85/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9888\n",
      "Epoch 00085: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 458us/sample - loss: 0.0460 - accuracy: 0.9882 - val_loss: 0.2326 - val_accuracy: 0.9537\n",
      "Epoch 86/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0301 - accuracy: 0.9920\n",
      "Epoch 00086: val_loss did not improve from 0.10181\n",
      "2719/2719 [==============================] - 1s 437us/sample - loss: 0.0298 - accuracy: 0.9923 - val_loss: 0.1099 - val_accuracy: 0.9724\n",
      "Epoch 87/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9970\n",
      "Epoch 00087: val_loss improved from 0.10181 to 0.09088, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 445us/sample - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.0909 - val_accuracy: 0.9757\n",
      "Epoch 88/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9970\n",
      "Epoch 00088: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 453us/sample - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.1739 - val_accuracy: 0.9691\n",
      "Epoch 89/100\n",
      "2640/2719 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9739\n",
      "Epoch 00089: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 431us/sample - loss: 0.1286 - accuracy: 0.9735 - val_loss: 0.2013 - val_accuracy: 0.9438\n",
      "Epoch 90/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9811\n",
      "Epoch 00090: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 443us/sample - loss: 0.0842 - accuracy: 0.9812 - val_loss: 0.1532 - val_accuracy: 0.9636\n",
      "Epoch 91/100\n",
      "2560/2719 [===========================>..] - ETA: 0s - loss: 0.0251 - accuracy: 0.9945\n",
      "Epoch 00091: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 444us/sample - loss: 0.0250 - accuracy: 0.9945 - val_loss: 0.1326 - val_accuracy: 0.9702\n",
      "Epoch 92/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9952\n",
      "Epoch 00092: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 439us/sample - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.1195 - val_accuracy: 0.9724\n",
      "Epoch 93/100\n",
      "2660/2719 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9951\n",
      "Epoch 00093: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 453us/sample - loss: 0.0271 - accuracy: 0.9949 - val_loss: 0.1612 - val_accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9889\n",
      "Epoch 00094: val_loss did not improve from 0.09088\n",
      "2719/2719 [==============================] - 1s 452us/sample - loss: 0.0504 - accuracy: 0.9890 - val_loss: 0.1185 - val_accuracy: 0.9735\n",
      "Epoch 95/100\n",
      "2680/2719 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9899\n",
      "Epoch 00095: val_loss improved from 0.09088 to 0.07503, saving model to opencon_model_aug_test2.h5\n",
      "2719/2719 [==============================] - 1s 456us/sample - loss: 0.0392 - accuracy: 0.9901 - val_loss: 0.0750 - val_accuracy: 0.9768\n",
      "Epoch 96/100\n",
      "2620/2719 [===========================>..] - ETA: 0s - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 00096: val_loss did not improve from 0.07503\n",
      "2719/2719 [==============================] - 1s 438us/sample - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.0755 - val_accuracy: 0.9802\n",
      "Epoch 97/100\n",
      "2580/2719 [===========================>..] - ETA: 0s - loss: 0.0151 - accuracy: 0.9973\n",
      "Epoch 00097: val_loss did not improve from 0.07503\n",
      "2719/2719 [==============================] - 1s 406us/sample - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.2580 - val_accuracy: 0.9592\n",
      "Epoch 98/100\n",
      "2600/2719 [===========================>..] - ETA: 0s - loss: 0.0468 - accuracy: 0.9904\n",
      "Epoch 00098: val_loss did not improve from 0.07503\n",
      "2719/2719 [==============================] - 1s 457us/sample - loss: 0.0453 - accuracy: 0.9908 - val_loss: 0.1048 - val_accuracy: 0.9746\n",
      "Epoch 99/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9963\n",
      "Epoch 00099: val_loss did not improve from 0.07503\n",
      "2719/2719 [==============================] - 1s 441us/sample - loss: 0.0220 - accuracy: 0.9956 - val_loss: 0.0832 - val_accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "2700/2719 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9944\n",
      "Epoch 00100: val_loss did not improve from 0.07503\n",
      "2719/2719 [==============================] - 1s 399us/sample - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.1259 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "filename = 'opencon_model_aug_test2.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#history = model.fit(x_train, y_train, epochs = 100, batch_size = 32, validation_split=0.2, verbose=1, callbacks=[checkpoint])\n",
    "history = model.fit(x_train, y_train, epochs = 100, batch_size = 20, validation_data= (x_val, y_val), verbose=1,callbacks=[checkpoint])\n",
    "\n",
    "##trying to reduce batch size and increase epochs to increase val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 27, 128)           177152    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 19)                1235      \n",
      "=================================================================\n",
      "Total params: 458,003\n",
      "Trainable params: 280,851\n",
      "Non-trainable params: 177,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotloss(history):\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['val_accuracy', 'Train_accuracy'], loc = 'lower right')\n",
    "    plt.show()\n",
    "    \n",
    "plotloss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907/907 [==============================] - 0s 159us/sample - loss: 0.1259 - accuracy: 0.9779\n",
      "97.79492616653442\n"
     ]
    }
   ],
   "source": [
    "_,acc=model.evaluate(x_val,y_val)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"opencon_model_aug_test2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "    test_word = word_tokenize(clean)\n",
    "    test_word = [w.lower() for w in test_word]\n",
    "    test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "    #print(test_word)            ##\n",
    "    #Check for unknown words\n",
    "    if [] in test_ls:\n",
    "        test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "    test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    " \n",
    "    x = padding_doc(test_ls, max_length)\n",
    "  \n",
    "    pred = model.predict_proba(x)\n",
    "  \n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "    predictions = pred[0]\n",
    " \n",
    "    classes = np.array(classes)\n",
    "    ids = np.argsort(-predictions)\n",
    "    classes = classes[ids]\n",
    "    predictions = -np.sort(-predictions)\n",
    "    pred_intent=classes[0]\n",
    " \n",
    "    #for i in range(pred.shape[1]):\n",
    "        #print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "    return pred_intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "text=\"need some help?\"\n",
    "pred = predictions(text)\n",
    "\n",
    "#predictions(text)\n",
    "get_final_output(pred, unique_intent)\n",
    "#word = word_for_id(pred, output_tokenizer)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_GQ_help = [\"Yes, I can help you with anything.\", \"What do you need help with?\", \"Sure. What can I help you with?\"]\n",
    "A_FAQ_why_reg = [\"Because there's no other event like this\", \"you will learn many new things\", \n",
    "             \" No other event which has both conference and hackathon\"]\n",
    "A_SQ_IEEE = [\"IEEE-VIT is one of the most active and prestigious chapters of VIT\", \"IEEE-VIT is a student technical chapter\",\n",
    "             \"IEEE-VIT is a student based chapter which falls under region 10\"]\n",
    "A_SQ_reg_fee = [\"No, the event is free to attend\", \"There is no registration fee for the event\", \"No, the registrations are free\"]\n",
    "A_GQ_name = [\"My name is IEEE bot\", \" I am IEEE bot\", \"You are talking to IEEE bot\"]\n",
    "A_FAQ_food = [\"Yes, food will be provided\",\"Yes, refreshments will be provided\",\"Sure, everyone needs food\"]\n",
    "A_GQ_query =[ \"Yes, go ahead\",\"Ask me any queries you have\",\"go ahead, ask away\"]\n",
    "A_GQ_bot = [\"That's right, I am a chatbot\", \"Yes, I am a chatbot\", \"I am a bot. Chatbot\"]\n",
    "A_SQ_event_details = [\"This event is all about learning\", \"It's a hackathon\",\"It's a fun event for sure\"]\n",
    "A_GQ_gen = [\"I am good\",\"I am doing great\",\"Never better\"]\n",
    "A_SQ_event_prize = [\"Yes, there will be prizes\",\"Definitely\",\"Yes there will be, along with goodies\"]\n",
    "A_FAQ_contact_info = [\"Please contact us via insta\",\"We are reachable from our insta handle\",\"You can contact us anytime via insta\"]\n",
    "A_JOIN = [\"Please contact us via collaborations.ieeevit@gmail.com, thank you.\"]\n",
    "A_SQ_event_speakers=[\"speaker 1 and 2 will join us, stay tuned for more\",\" We have confirmed speaker 1 and 2\"]\n",
    "A_SQ_event_date=[\"From 10th to 12th\",\"It will be for 2 days starting from 10th\",\"10th-12th\"]\n",
    "A_SQ_reg_lastdate=[\"The last day to register is 9th\",\"You can register by 9th\",\"9th is the last day to register\"]\n",
    "A_SQ_event_schedule=[\"There will be talks followed by a hackthon\",\"First talks then hack\",\"Hack after speech\"]\n",
    "A_FAQ_accom=[\"No, accomodation can't be provided\",\"Sorry, we dont provide accomodation\",\"There is no accomodation facility from our side\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def F1():\n",
    "    print('bot: ',random.choice(A_GQ_help))\n",
    "def F2():\n",
    "    print('bot: ',random.choice(A_FAQ_why_reg))\n",
    "def F3():\n",
    "    print('bot: ',random.choice(A_SQ_IEEE))\n",
    "def F4():\n",
    "    print('bot: ',random.choice(A_SQ_reg_fee))\n",
    "def F5():\n",
    "    print('bot: ',random.choice(A_GQ_name))\n",
    "def F6():\n",
    "    print('bot: ',random.choice(A_FAQ_food))\n",
    "def F7():\n",
    "    print('bot: ',random.choice(A_GQ_query))\n",
    "def F8():\n",
    "    print('bot: ',random.choice(A_GQ_bot))\n",
    "def F9():\n",
    "    print('bot: ',random.choice(A_SQ_event_details))\n",
    "def F10():\n",
    "    print('bot: ',random.choice(A_GQ_gen))\n",
    "def F11():\n",
    "    print('bot: ',random.choice(A_SQ_event_prize))\n",
    "def F12():\n",
    "    print('bot: ',random.choice(A_FAQ_contact_info))\n",
    "def F13():\n",
    "    print('bot: ',random.choice(A_JOIN))\n",
    "def F14():\n",
    "    print('bot: ',random.choice(A_SQ_event_speakers))\n",
    "def F15():\n",
    "    print('bot: ',random.choice(A_SQ_event_date))\n",
    "def F16():\n",
    "    print('bot: ',random.choice(A_SQ_reg_lastdate))\n",
    "def F17():\n",
    "    print('bot: ',random.choice(A_SQ_event_schedule))\n",
    "def F18():\n",
    "    print('bot: ',random.choice(A_FAQ_accom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_output():\n",
    "    for i in range(100):\n",
    "        text=input('\\nYou: ')\n",
    "        if text == 'quit':\n",
    "            print('bye')\n",
    "            break\n",
    "        else : \n",
    "            pred = predictions(text)\n",
    "            if get_final_output(pred, unique_intent) == 'GQ.help':\n",
    "                F1()\n",
    "            elif get_final_output(pred, unique_intent) == 'FAQ.why_reg':\n",
    "                F2()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.IEEE':\n",
    "                F3()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.reg_fee':\n",
    "                F4()\n",
    "            elif get_final_output(pred, unique_intent) == 'GQ.name':\n",
    "                F5()\n",
    "            elif get_final_output(pred, unique_intent) == 'FAQ.food':\n",
    "                F6()\n",
    "            elif get_final_output(pred, unique_intent) == 'GQ.query':\n",
    "                F7()\n",
    "            elif get_final_output(pred, unique_intent) == 'GQ.bot':\n",
    "                F8()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.event_details':\n",
    "                F9()\n",
    "            elif get_final_output(pred, unique_intent) == 'GQ.gen':\n",
    "                F10()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.event_prize':\n",
    "                F11()\n",
    "            elif get_final_output(pred, unique_intent) == 'FAQ.contact_info':\n",
    "                F12()\n",
    "            elif get_final_output(pred, unique_intent) == 'JOIN.speaker':\n",
    "                F13()\n",
    "            elif get_final_output(pred, unique_intent) == 'JOIN.sponsor':\n",
    "                F13()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.event_speakers':\n",
    "                F14()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.event_date':\n",
    "                F15()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.reg_lastdate':\n",
    "                F16()\n",
    "            elif get_final_output(pred, unique_intent) == 'SQ.event_schedule':\n",
    "                F17()\n",
    "            elif get_final_output(pred, unique_intent) == 'FAQ.accom':\n",
    "                F18()\n",
    "            else:\n",
    "                print(\"Please enter a valid response\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: I want to speak\n",
      "bot:  Please contact us via collaborations.ieeevit@gmail.com, thank you.\n",
      "\n",
      "You: last date to register?\n",
      "bot:  You can register by 9th\n",
      "\n",
      "You: what about refreshments?\n",
      "bot:  Yes, refreshments will be provided\n",
      "\n",
      "You: quit\n",
      "bye\n"
     ]
    }
   ],
   "source": [
    "user_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dlmodel] *",
   "language": "python",
   "name": "conda-env-.conda-dlmodel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
