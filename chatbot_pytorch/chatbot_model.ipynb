{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'airline_intent_dataset.csv',\n",
       " 'Bot.ipynb',\n",
       " 'bot.pt',\n",
       " 'cb_dataset_cleaned - Sheet1.csv',\n",
       " 'chatbot_1_model.ipynb',\n",
       " 'data',\n",
       " 'drop_dataset',\n",
       " 'drop_dataset.zip',\n",
       " 'embed.npy',\n",
       " 'embed.pt',\n",
       " 'flight_a.txt',\n",
       " 'flight_data.ipynb',\n",
       " 'flight_q.txt',\n",
       " 'gg.ipynb',\n",
       " 'good_one.json',\n",
       " 'home',\n",
       " 'intent.txt',\n",
       " 'intent_int.txt',\n",
       " 'int_to_vocab.txt',\n",
       " 'opencon_dataset_augmented2.csv',\n",
       " 'open_a.txt',\n",
       " 'Open_con_Dataset.ipynb',\n",
       " 'open_q.txt',\n",
       " 'preprocessing_chat_bot.ipynb',\n",
       " 'preprocessing_chat_bot.ipynb - Shortcut.lnk',\n",
       " 'preprocessing_chat_bot.py',\n",
       " 'sentrence.txt',\n",
       " 'sentrence_int.txt',\n",
       " 'skipgram.pth',\n",
       " 'skipgram_embed_intent_bot.pt',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " 'utils.py',\n",
       " 'vocab_to_int.txt',\n",
       " 'weight.pt',\n",
       " 'workspace-1607731597.tar.gz',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('opencon_dataset_augmented2.csv') \n",
    "data=csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=[]\n",
    "answer=[]\n",
    "for i in data:\n",
    "    question.append(i[0])\n",
    "    answer.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot',\n",
       " 'GQ.bot']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is there a bot chatting to me?',\n",
       " 'Is it automated message?',\n",
       " 'Computer based pely',\n",
       " 'Bot or human?',\n",
       " 'Bot is chatting with me?',\n",
       " 'Are you system generated message?',\n",
       " 'Are you robot?',\n",
       " 'Are you machine?',\n",
       " 'Are you just computer?',\n",
       " 'Are you a robot?',\n",
       " 'Are you a person?',\n",
       " 'Are you a machine?',\n",
       " 'Are you a chatbot?',\n",
       " 'Are you a bot?',\n",
       " 'Are these automated messages?',\n",
       " 'Am I talking to a bot?',\n",
       " 'You are a boy are girl?',\n",
       " 'You are a bot or human?',\n",
       " 'This is a machine?',\n",
       " 'This is a chatbot?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAQ.accom',\n",
       " 'SQ.event_prize',\n",
       " 'SQ.event_speakers',\n",
       " 'GQ.help',\n",
       " 'GQ.bot',\n",
       " 'GQ.name',\n",
       " 'FAQ.contact_info',\n",
       " 'JOIN.sponsor',\n",
       " 'SQ.event_details',\n",
       " 'SQ.reg_fee',\n",
       " 'FAQ.food',\n",
       " 'SQ.reg_lastdate',\n",
       " 'FAQ.why_reg',\n",
       " 'SQ.event_schedule',\n",
       " 'JOIN.speaker',\n",
       " 'GQ.gen',\n",
       " 'SQ.IEEE',\n",
       " 'GQ.query',\n",
       " 'SQ.event_date']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent=list(set(answer))\n",
    "intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_int={}\n",
    "int_intent={}\n",
    "for i,j in enumerate(intent):\n",
    "    intent_int.update({j:i})\n",
    "for i,j in intent_int.items():\n",
    "    int_intent.update({i:j})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces_1(text):\n",
    "\n",
    "    # Replace punctuation with tokens so we can use them in our model\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' <PERIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
    "    text = text.replace(':', ' <COLON> ')\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove all words with  5 or fewer occurences\n",
    "    word_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if word_counts[word] > 5]\n",
    "\n",
    "    return trimmed_words\n",
    "\n",
    "\n",
    "def preproces_2(text):\n",
    "\n",
    "    # Replace punctuation with tokens so we can use them in our model\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' <PERIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
    "    text = text.replace(':', ' <COLON> ')\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove all words with  5 or fewer occurences\n",
    "    word_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if word_counts[word] > 0]\n",
    "\n",
    "    return trimmed_words\n",
    "\n",
    "def create_lookup_tables(words):\n",
    "    word_counts = Counter(words)\n",
    "    # sorting the words from most to least frequent in text occurrence\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    # create int_to_vocab dictionaries\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'it', 'automated', 'message', '<QUESTION_MARK>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproces_2(question[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_p=[]\n",
    "for i in question:\n",
    "    sent=' '.join(preproces_2(i))+\"\\n\"\n",
    "    question_p.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for i in question_p:\n",
    "    for j in i.split():\n",
    "        words.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interested',\n",
       " 'covered',\n",
       " 'below',\n",
       " 'keep',\n",
       " 'un',\n",
       " '2016',\n",
       " 'number',\n",
       " 'march',\n",
       " 'somehow',\n",
       " 'article',\n",
       " 'named',\n",
       " 'placed',\n",
       " 'let',\n",
       " 'dress',\n",
       " 'host',\n",
       " 'intended',\n",
       " 'annual',\n",
       " '2020',\n",
       " 'planned',\n",
       " 'he']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is there a bot chatting to me <QUESTION_MARK>\\n',\n",
       " 'is it automated message <QUESTION_MARK>\\n',\n",
       " 'computer based pely\\n',\n",
       " 'bot or human <QUESTION_MARK>\\n',\n",
       " 'bot is chatting with me <QUESTION_MARK>\\n',\n",
       " 'are you system generated message <QUESTION_MARK>\\n',\n",
       " 'are you robot <QUESTION_MARK>\\n',\n",
       " 'are you machine <QUESTION_MARK>\\n',\n",
       " 'are you just computer <QUESTION_MARK>\\n',\n",
       " 'are you a robot <QUESTION_MARK>\\n',\n",
       " 'are you a person <QUESTION_MARK>\\n',\n",
       " 'are you a machine <QUESTION_MARK>\\n',\n",
       " 'are you a chatbot <QUESTION_MARK>\\n',\n",
       " 'are you a bot <QUESTION_MARK>\\n',\n",
       " 'are these automated messages <QUESTION_MARK>\\n',\n",
       " 'am i talking to a bot <QUESTION_MARK>\\n',\n",
       " 'you are a boy are girl <QUESTION_MARK>\\n',\n",
       " 'you are a bot or human <QUESTION_MARK>\\n',\n",
       " 'this is a machine <QUESTION_MARK>\\n',\n",
       " 'this is a chatbot <QUESTION_MARK>\\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_p[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(set(words))\n",
    "int_to_words={}\n",
    "words_to_int={}\n",
    "for i,j in enumerate(words,1):\n",
    "    int_to_words.update({i:j})\n",
    "for i,j in int_to_words.items():\n",
    "    words_to_int.update({j:i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_int=[]\n",
    "for i in question_p:\n",
    "    question_int=[]\n",
    "    for j in i.split():\n",
    "        if j in words:\n",
    "            question_int.append(words_to_int[j])\n",
    "    if len(question_int):    \n",
    "        questions_int.append(question_int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1187, 781, 715, 1184, 485, 78, 194, 216]),\n",
       "       list([1187, 704, 72, 1169, 216]), list([1209, 663, 879]),\n",
       "       list([1184, 822, 1213, 216]),\n",
       "       list([1184, 1187, 485, 58, 194, 216]),\n",
       "       list([247, 1391, 220, 1073, 1169, 216]),\n",
       "       list([247, 1391, 1339, 216]), list([247, 1391, 883, 216]),\n",
       "       list([247, 1391, 64, 1209, 216]),\n",
       "       list([247, 1391, 715, 1339, 216]),\n",
       "       list([247, 1391, 715, 1031, 216]),\n",
       "       list([247, 1391, 715, 883, 216]), list([247, 1391, 715, 784, 216]),\n",
       "       list([247, 1391, 715, 1184, 216]), list([247, 484, 72, 933, 216]),\n",
       "       list([1222, 763, 1136, 78, 715, 1184, 216]),\n",
       "       list([1391, 247, 715, 554, 247, 424, 216]),\n",
       "       list([1391, 247, 715, 1184, 822, 1213, 216]),\n",
       "       list([431, 1187, 715, 883, 216]), list([431, 1187, 715, 784, 216])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_int[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "questions_int=np.array(questions_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0 1187 ...   78  194  216]\n",
      " [   0    0    0 ...   72 1169  216]\n",
      " [   0    0    0 ... 1209  663  879]\n",
      " ...\n",
      " [1207   78  959 ...  800  431  611]\n",
      " [ 522 1041  522 ... 1168 1391  759]\n",
      " [ 207  522 1187 ...  193  203  203]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "\n",
    "features = pad_features(questions_int, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "#assert len(features)==len(sentrences.split('\\n')[:20]), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_set=list(set(answer))\n",
    "ans_to_int={}\n",
    "int_to_ans={}\n",
    "for i,j in enumerate(ans_set):\n",
    "    int_to_ans.update({i:j})\n",
    "for i,j in int_to_ans.items():\n",
    "    ans_to_int.update({j:i})\n",
    "master_intent=[]\n",
    "for i in answer:\n",
    "    master_intent.append(ans_to_int[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_intent[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(3263, 10) \n",
      "Validation set: \t(181, 10) \n",
      "Test set: \t\t(182, 10)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.9\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = master_intent[:split_idx], master_intent[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "valid_data = TensorDataset(torch.Tensor(val_x), torch.Tensor(val_y))\n",
    "test_data = TensorDataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 1\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([1, 10])\n",
      "Sample input: \n",
      " tensor([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,   20., 1010.,  216.]])\n",
      "\n",
      "Sample label size:  torch.Size([1])\n",
      "Sample label: \n",
      " tensor([15.])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Semantic_Classifier(nn.Module):\n",
    "   \n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(Semantic_Classifier, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "       \n",
    "        batch_size = x.size(0)\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        out = self.fc(torch.cat((torch.squeeze(hidden[0]),torch.squeeze(hidden[1])),0))\n",
    "       \n",
    "        sig_out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic_Classifier(\n",
      "  (embedding): Embedding(1411, 300)\n",
      "  (lstm): LSTM(300, 256, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=19, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words_to_int)+1\n",
    "output_size = 19\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "n_layers = 1\n",
    "\n",
    "# net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "net_1=Semantic_Classifier(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Step: 1000... Loss: 2.031302214... Val Accuracy: 96.13%... Val Loss: 2.031017\n",
      "Epoch: 1/10... Step: 2000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.031022\n",
      "Epoch: 1/10... Step: 3000... Loss: 2.033260107... Val Accuracy: 94.48%... Val Loss: 2.031017\n",
      "Epoch: 2/10... Step: 4000... Loss: 2.031016588... Val Accuracy: 95.03%... Val Loss: 2.031021\n",
      "Epoch: 2/10... Step: 5000... Loss: 2.031016588... Val Accuracy: 95.58%... Val Loss: 2.031018\n",
      "Epoch: 2/10... Step: 6000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.044963\n",
      "Epoch: 3/10... Step: 7000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.055459\n",
      "Epoch: 3/10... Step: 8000... Loss: 2.031019688... Val Accuracy: 94.48%... Val Loss: 2.031017\n",
      "Epoch: 3/10... Step: 9000... Loss: 2.031021595... Val Accuracy: 95.03%... Val Loss: 2.031017\n",
      "Epoch: 4/10... Step: 10000... Loss: 2.110691547... Val Accuracy: 93.92%... Val Loss: 2.031029\n",
      "Epoch: 4/10... Step: 11000... Loss: 2.031021118... Val Accuracy: 95.03%... Val Loss: 2.110690\n",
      "Epoch: 4/10... Step: 12000... Loss: 2.031016588... Val Accuracy: 95.58%... Val Loss: 2.031017\n",
      "Epoch: 4/10... Step: 13000... Loss: 2.031017542... Val Accuracy: 95.58%... Val Loss: 2.031017\n",
      "Epoch: 5/10... Step: 14000... Loss: 2.031016588... Val Accuracy: 96.13%... Val Loss: 2.031017\n",
      "Epoch: 5/10... Step: 15000... Loss: 2.031017065... Val Accuracy: 95.03%... Val Loss: 2.031017\n",
      "Epoch: 5/10... Step: 16000... Loss: 2.031016588... Val Accuracy: 95.58%... Val Loss: 2.031017\n",
      "Epoch: 6/10... Step: 17000... Loss: 2.031016588... Val Accuracy: 95.58%... Val Loss: 2.031018\n",
      "Epoch: 6/10... Step: 18000... Loss: 2.031017542... Val Accuracy: 94.48%... Val Loss: 2.031018\n",
      "Epoch: 6/10... Step: 19000... Loss: 2.031017303... Val Accuracy: 95.03%... Val Loss: 2.031017\n",
      "Epoch: 7/10... Step: 20000... Loss: 2.031017780... Val Accuracy: 94.48%... Val Loss: 2.082215\n",
      "Epoch: 7/10... Step: 21000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.031107\n",
      "Epoch: 7/10... Step: 22000... Loss: 2.031016588... Val Accuracy: 96.13%... Val Loss: 2.031017\n",
      "Epoch: 8/10... Step: 23000... Loss: 2.031016588... Val Accuracy: 96.13%... Val Loss: 2.031017\n",
      "Epoch: 8/10... Step: 24000... Loss: 2.031016588... Val Accuracy: 96.13%... Val Loss: 2.031034\n",
      "Epoch: 8/10... Step: 25000... Loss: 2.031025887... Val Accuracy: 96.13%... Val Loss: 2.031093\n",
      "Epoch: 8/10... Step: 26000... Loss: 2.031016588... Val Accuracy: 95.03%... Val Loss: 2.032411\n",
      "Epoch: 9/10... Step: 27000... Loss: 2.031016588... Val Accuracy: 96.13%... Val Loss: 2.031022\n",
      "Epoch: 9/10... Step: 28000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.031167\n",
      "Epoch: 9/10... Step: 29000... Loss: 2.031016588... Val Accuracy: 95.58%... Val Loss: 2.031017\n",
      "Epoch: 10/10... Step: 30000... Loss: 2.031016588... Val Accuracy: 95.03%... Val Loss: 2.031017\n",
      "Epoch: 10/10... Step: 31000... Loss: 2.031016588... Val Accuracy: 94.48%... Val Loss: 2.031017\n",
      "Epoch: 10/10... Step: 32000... Loss: 2.031016588... Val Accuracy: 95.03%... Val Loss: 2.031017\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net_1.cuda()\n",
    "\n",
    "net_1.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    net_1.train()\n",
    "    h = net_1.init_hidden(batch_size)\n",
    "    \n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            inputs=torch.tensor(inputs).to(torch.int64)\n",
    "            labels=torch.tensor(labels).to(torch.long)\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net_1.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        net_1.train()\n",
    "        output, h = net_1(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net_1.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            net_1.eval()\n",
    "            val_h = net_1.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            a=[]\n",
    "            net_1.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                \n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                    inputs=torch.tensor(inputs).to(torch.int64)\n",
    "                    labels=torch.tensor(labels).to(torch.long)\n",
    "\n",
    "                output, val_h = net_1(inputs, val_h)\n",
    "                _,index=torch.topk(output,1)\n",
    "                val_loss = criterion(output, labels)\n",
    "                a.append(index.item()==labels.item())\n",
    "            a=100*((a.count(1))/(a.count(0)+a.count(1)))\n",
    "                \n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.9f}...\".format(loss.item()),\n",
    "                  \"Val Accuracy: {:.2f}%...\".format(a),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you need tell him more funds <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "will you you always feed us <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "will that be we be the provided with food during OUTPUT: FAQ.food\n",
      "who other should i talk to to OUTPUT: FAQ.contact_info\n",
      "and when can do i speak at <PERIOD> <PERIOD> <PERIOD> OUTPUT: JOIN.speaker\n",
      "but i am just a terrible family foodie <EXCLAMATION_MARK> will OUTPUT: FAQ.food\n",
      "so if is there a place appropriate for speaker in OUTPUT: JOIN.speaker\n",
      "what though what can fields do all things you need OUTPUT: JOIN.speaker\n",
      "why are ya we gonna be provided such food OUTPUT: FAQ.food\n",
      "when do you have long enough for funding <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "such as would accommodation be on free charge or paid OUTPUT: FAQ.accom\n",
      "as will the food would be better provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "i would also like to deliver us a long oral OUTPUT: JOIN.speaker\n",
      "how to eventually do i apply to be this almost OUTPUT: JOIN.speaker\n",
      "how much can today we apply for sponsorship <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "what will be presently already provided to buy these new OUTPUT: SQ.event_speakers\n",
      "how to sponsor golf on the saturday event <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "also <PERIOD> <PERIOD> <PERIOD> are there there any large accommodations OUTPUT: FAQ.accom\n",
      "â« a â« how well can i join to join OUTPUT: JOIN.speaker\n",
      "her other phone OUTPUT: FAQ.contact_info\n",
      "or do you actually provide accommodation <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "i can stay so we contact for you for possible OUTPUT: JOIN.sponsor\n",
      "but when will will there be any vegan food <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "one iam willing members to formally contribute money for arranging OUTPUT: JOIN.sponsor\n",
      "so who to contact him for their further human doubts OUTPUT: FAQ.contact_info\n",
      "but wherein would food be provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "how to initiate some contact here the general organisation committee OUTPUT: FAQ.contact_info\n",
      "and what is not the criteria are required <PERIOD> <PERIOD> OUTPUT: JOIN.speaker\n",
      "what about just your lunch <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "but will food not be provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "why even should shall i register <QUESTION_MARK> OUTPUT: FAQ.why_reg\n",
      "had contact with info <QUESTION_MARK> OUTPUT: FAQ.contact_info\n",
      "can a sponsor even just join <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "like exactly what'd s so special about hosting <PERIOD> <PERIOD> OUTPUT: FAQ.why_reg\n",
      "i want to also new sponsor organizing this event OUTPUT: JOIN.sponsor\n",
      "and could you always provide the precise details of specific OUTPUT: FAQ.contact_info\n",
      "at what if a speaker really wants to possibly help OUTPUT: JOIN.speaker\n",
      "whom to contact even if even i should really want OUTPUT: JOIN.speaker\n",
      "will eventually there be any suitable accommodation options for meeting OUTPUT: FAQ.accom\n",
      "<PERIOD> <PERIOD> <PERIOD> who should if i ever contact OUTPUT: FAQ.contact_info\n",
      "can all our members company possibly be a part member OUTPUT: JOIN.sponsor\n",
      "do how we get food and during the whole cultural OUTPUT: FAQ.food\n",
      "if is there any requirements yet above for maintaining your OUTPUT: JOIN.speaker\n",
      "but why should i come back for us this in OUTPUT: FAQ.why_reg\n",
      "i am really willing anyone below to give us all OUTPUT: JOIN.speaker\n",
      "exactly what exactly was about refreshments <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "what help will i ever gain out by suddenly joining OUTPUT: FAQ.why_reg\n",
      "can i go and live there outside the downtown washington OUTPUT: FAQ.accom\n",
      "where is food usually included OUTPUT: FAQ.food\n",
      "and would pizza'o restaurant like s be provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "why should i always always fund fund of your event OUTPUT: JOIN.sponsor\n",
      "why should never i always register <QUESTION_MARK> OUTPUT: FAQ.why_reg\n",
      "no but whom should i contact <QUESTION_MARK> OUTPUT: FAQ.contact_info\n",
      "from whom further do they i need to be contact OUTPUT: FAQ.contact_info\n",
      "why then also should we each register ourselves for the OUTPUT: FAQ.why_reg\n",
      "how are are there arrangements for two visiting vegetarians <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "surely we both would simply like to sponsor your homecoming OUTPUT: JOIN.sponsor\n",
      "so will there be any less free food <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "would future food making arrangements be free of the interest OUTPUT: FAQ.food\n",
      "i have did some more general job a query then OUTPUT: FAQ.contact_info\n",
      "then can may i please serve come as a speaker OUTPUT: JOIN.speaker\n",
      "what exactly are you willing to please or speak some OUTPUT: JOIN.speaker\n",
      "also is there any vacancy out here looking for more OUTPUT: JOIN.speaker\n",
      "what are about the benefits for having me start attending OUTPUT: FAQ.why_reg\n",
      "those whom better advised to contact for more information OUTPUT: FAQ.contact_info\n",
      "for me who do think i contact him to regarding OUTPUT: FAQ.contact_info\n",
      "want us to further sponsor your event OUTPUT: JOIN.sponsor\n",
      "i more personally would like her offer to sponsor opencon OUTPUT: JOIN.sponsor\n",
      "how to be at a prominent and part outside of OUTPUT: JOIN.speaker\n",
      "or if is there non - korean vegetarian comfort food OUTPUT: FAQ.food\n",
      "where will there truly be stalls <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "what or what will and i get out of of OUTPUT: FAQ.why_reg\n",
      "why also should <PERIOD> <PERIOD> <PERIOD> i deliberately choose opencon OUTPUT: FAQ.why_reg\n",
      "what more about ending our stay OUTPUT: FAQ.accom\n",
      "and would you still behave like asked to discuss more OUTPUT: JOIN.sponsor\n",
      "whom exactly can be i contact <QUESTION_MARK> OUTPUT: FAQ.contact_info\n",
      "where from now can i stay <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "what will think i cannot really get out of and OUTPUT: FAQ.why_reg\n",
      "will have proper refreshments provide be provided OUTPUT: FAQ.food\n",
      "then will win this event be worth wallet <QUESTION_MARK> OUTPUT: FAQ.why_reg\n",
      "why should if not we register <QUESTION_MARK> OUTPUT: FAQ.why_reg\n",
      "i also want me to probably be a speaker host OUTPUT: JOIN.speaker\n",
      "what variety <PERIOD> <PERIOD> <PERIOD> are the foods actually offered OUTPUT: FAQ.food\n",
      "how true but can someone be a slightly better speaker OUTPUT: JOIN.speaker\n",
      "i would really like them to better sponsor some you OUTPUT: JOIN.sponsor\n",
      "for how is my it gone and a help depends OUTPUT: FAQ.why_reg\n",
      "i too would particularly like half them ready to speak OUTPUT: JOIN.speaker\n",
      "what is accommodation really free <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "what food arrangements <PERIOD> <PERIOD> <PERIOD> shall he be taken OUTPUT: FAQ.food\n",
      "and what benefits need that would enable i get to OUTPUT: FAQ.why_reg\n",
      "is your liquid finance done but just get back to OUTPUT: JOIN.sponsor\n",
      "whom i can suggest we eventually contact him again for OUTPUT: FAQ.contact_info\n",
      "why should i even register automatically for suddenly this big OUTPUT: FAQ.why_reg\n",
      "i never want to be sponsor OUTPUT: JOIN.sponsor\n",
      "is awaiting additional accommodation provided OUTPUT: FAQ.accom\n",
      "or why should am i register to file for no OUTPUT: FAQ.why_reg\n",
      "how often will they can and we not be properly OUTPUT: FAQ.accom\n",
      "wherever will accommodation now be arranged <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "that is even there any actual proper organic food arrangement OUTPUT: FAQ.food\n",
      "what is precisely the benefit ahead ahead of attending this OUTPUT: FAQ.why_reg\n",
      "so is there or there also any slot available locally OUTPUT: JOIN.speaker\n",
      "who can say i now ever call for in our OUTPUT: FAQ.contact_info\n",
      "will food often be warmly provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "but why should have i come alive only to cancel OUTPUT: FAQ.why_reg\n",
      "whom can now have i contact in life this special OUTPUT: FAQ.contact_info\n",
      "when will a food be provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "how soon do i ever <PERIOD> <PERIOD> <PERIOD> reach for OUTPUT: JOIN.sponsor\n",
      "but how more can i sponsor this famous event OUTPUT: JOIN.sponsor\n",
      "<PERIOD> <PERIOD> <PERIOD> what diseases are are you willing willing OUTPUT: JOIN.sponsor\n",
      "will food be present when provided OUTPUT: FAQ.food\n",
      "but well what are the current accommodations provided <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "there at all are many unique national events why should OUTPUT: FAQ.why_reg\n",
      "i i would also greatly like to now be onboard OUTPUT: JOIN.speaker\n",
      "what point is special about not reaching outside the event OUTPUT: FAQ.why_reg\n",
      "or <PERIOD> <PERIOD> <PERIOD> what are making the arrangements for OUTPUT: FAQ.food\n",
      "i could still just have some further doubts i want OUTPUT: FAQ.contact_info\n",
      "what time would at all it take be ac / OUTPUT: FAQ.accom\n",
      "what does this new place do well for me OUTPUT: FAQ.why_reg\n",
      "now how can i reach into anything the news event OUTPUT: FAQ.contact_info\n",
      "depending who they can tell do i contact or anyone OUTPUT: FAQ.contact_info\n",
      "after all it fit the details of the office accommodation OUTPUT: FAQ.accom\n",
      "will u provide available overnight accommodation or during the main OUTPUT: FAQ.accom\n",
      "how to sponsor the super football bowl event <QUESTION_MARK> OUTPUT: JOIN.sponsor\n",
      "do do we ever have to get past our because OUTPUT: FAQ.food\n",
      "like with what's so freaking incredibly special out tonight about OUTPUT: FAQ.why_reg\n",
      "then i simply would like you someone to willingly join OUTPUT: JOIN.sponsor\n",
      "any certain future benefits for funding activities of your own OUTPUT: JOIN.sponsor\n",
      "can i she i not stay often with a friend OUTPUT: FAQ.accom\n",
      "who cares ever can i really get contact for my OUTPUT: FAQ.contact_info\n",
      "or what book is also so incredibly special written in OUTPUT: FAQ.why_reg\n",
      "or is there enough food <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "what size is the current accommodation requirement situation <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "now where will insist i stay <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "what better form of outside help are your all a OUTPUT: JOIN.sponsor\n",
      "can still we i get some numbers OUTPUT: FAQ.contact_info\n",
      "oh do ya do know we already get the right OUTPUT: SQ.event_prize\n",
      "what came about certain free food / video travel refreshments OUTPUT: FAQ.food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how then can i help someone with the event OUTPUT: JOIN.sponsor\n",
      "tell them whom to contact <QUESTION_MARK> OUTPUT: FAQ.contact_info\n",
      "to where can should i stay <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "of what number is the menu <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "because how many do know we now have to pay OUTPUT: SQ.reg_fee\n",
      "what point is the procedure to finally actually become a OUTPUT: JOIN.speaker\n",
      "say what are th end arrangements u for food OUTPUT: FAQ.food\n",
      "so i want to <PERIOD> <PERIOD> <PERIOD> speak OUTPUT: JOIN.speaker\n",
      "but what else do we now achieve just by the OUTPUT: FAQ.why_reg\n",
      "had i interested in sponsoring him quite the event OUTPUT: JOIN.sponsor\n",
      "give me set up the contact info of meeting someone OUTPUT: FAQ.contact_info\n",
      "how many can only i speak please at your event OUTPUT: JOIN.speaker\n",
      "then why should i dare come <QUESTION_MARK> OUTPUT: FAQ.why_reg\n",
      "who should would i possibly contact for accommodation from health OUTPUT: FAQ.contact_info\n",
      "for how much can someone truly be a bad sponsor OUTPUT: JOIN.sponsor\n",
      "who can a speaker not join <QUESTION_MARK> OUTPUT: JOIN.speaker\n",
      "where are they there there arrangements made for non african OUTPUT: FAQ.food\n",
      "and what changes there if a sponsor really wants to OUTPUT: JOIN.sponsor\n",
      "i need more for a help OUTPUT: FAQ.contact_info\n",
      "who who can shall i now contact for immediate queries OUTPUT: FAQ.contact_info\n",
      "well what good r we never gonna get from al OUTPUT: FAQ.why_reg\n",
      "why was this event and what not before why followed OUTPUT: FAQ.why_reg\n",
      "whom was to ever contact me for sponsorship of purposes OUTPUT: JOIN.sponsor\n",
      "plus who and then should i maybe call contact for OUTPUT: FAQ.contact_info\n",
      "how odd to be so a part accused of securing OUTPUT: JOIN.speaker\n",
      "will this someday we provided two rooms between downstairs or OUTPUT: FAQ.accom\n",
      "where do whether i eventually stay <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "what just is most interesting <PERIOD> <PERIOD> <PERIOD> about this OUTPUT: FAQ.why_reg\n",
      "will their food be ever provided <QUESTION_MARK> OUTPUT: FAQ.food\n",
      "can i actually actually become a speaker OUTPUT: JOIN.speaker\n",
      "but i <PERIOD> <PERIOD> <PERIOD> just would still like to OUTPUT: JOIN.speaker\n",
      "and contact details number of organisers OUTPUT: FAQ.contact_info\n",
      "why should i do i only secretly register for this OUTPUT: FAQ.why_reg\n",
      "whom anybody can say i contact just now for more OUTPUT: FAQ.contact_info\n",
      "or how can both you advertise her for hurting me OUTPUT: JOIN.sponsor\n",
      "where can say to i register all ourselves as sponsors OUTPUT: JOIN.sponsor\n",
      "but maybe i still want even more personal personal details OUTPUT: FAQ.contact_info\n",
      "why should then we not register this everyone for hosting OUTPUT: FAQ.why_reg\n",
      "can <PERIOD> <PERIOD> <PERIOD> would i stay long outside campus OUTPUT: FAQ.accom\n",
      "surely would accommodation indeed be something often best provided in OUTPUT: FAQ.accom\n",
      "just what are the benefits ahead in sponsoring a host OUTPUT: JOIN.sponsor\n",
      "why should i register opposite her for just this upcoming OUTPUT: FAQ.why_reg\n",
      "who can argue i but contact you for more comprehensive OUTPUT: FAQ.contact_info\n",
      "and would private transportation to college and campus be provided OUTPUT: JOIN.speaker\n",
      "and is it not there any general email for id OUTPUT: FAQ.contact_info\n",
      "Val Loss: 2.061944         Val_Acuuracy: 98.35164835164835\n"
     ]
    }
   ],
   "source": [
    "net_1.eval()\n",
    "val_h = net_1.init_hidden(batch_size)\n",
    "val_losses = []\n",
    "a=[]\n",
    "net_1.eval()\n",
    "for inputs, labels in test_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                inputs=torch.tensor(inputs).to(torch.int64)\n",
    "                labels=torch.tensor(labels).to(torch.long)\n",
    "                \n",
    "        output, val_h = net_1(inputs, val_h)\n",
    "        _,index=torch.topk(output,1)\n",
    "        a.append(index.item()==labels.item())\n",
    "        val_loss = criterion(output, labels)\n",
    "        for i in inputs.squeeze():\n",
    "            if i:\n",
    "                print(int_to_words[i.item()],end=\" \")\n",
    "        print('OUTPUT:',int_to_ans[index.item()])\n",
    "                \n",
    "        \n",
    "        \n",
    "        val_losses.append(val_loss.item())\n",
    "print( \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\"        Val_Acuuracy:\",(a.count(1)/(a.count(0)+a.count(1)))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Guru Aathavan AL U\\code\\Ana_conda\\envs\\pytorch_cuda_trail\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perhaps but what is the reward <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "perhaps what will ever i get <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "one when does the loop even start of and and OUTPUT: SQ.event_date\n",
      "besides when will ever the speakers not actually be coming OUTPUT: SQ.event_speakers\n",
      "<PERIOD> <PERIOD> <PERIOD> what's the proper event time and have OUTPUT: SQ.event_date\n",
      "now when when is it <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "and will the only prize awarded be from cash or OUTPUT: SQ.event_prize\n",
      "what is the maximum planned time release this span allowed OUTPUT: SQ.event_date\n",
      "what or other domains / other specializations else are all OUTPUT: SQ.event_speakers\n",
      "then what whatas there were in the time table for OUTPUT: SQ.event_schedule\n",
      "who are the new main speakers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "but do the normal people running away who maybe didn't OUTPUT: SQ.event_prize\n",
      "no internal speakers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "what is against the current last registration date set up OUTPUT: SQ.reg_lastdate\n",
      "is there a first person winner and prize <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "but what is this all about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "what often follows is the timeline of analyzing for the OUTPUT: SQ.event_schedule\n",
      "when here is the event event already planned or to OUTPUT: SQ.event_date\n",
      "basically what is is this it just during a conference OUTPUT: SQ.event_schedule\n",
      "so what will we do for them water accommodation OUTPUT: FAQ.accom\n",
      "that or else are there there any prizes for winners OUTPUT: SQ.event_prize\n",
      "do runner ups get punished for saying something <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "and on which dates or will the current event be OUTPUT: SQ.event_date\n",
      "what corporation is currently controlling the fall schedule for the OUTPUT: SQ.event_date\n",
      "what are the bigger prize prizes like for movie winners OUTPUT: SQ.event_prize\n",
      "what is it for the prize and money <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "and which current day to which a future day is OUTPUT: SQ.event_date\n",
      "s what'd s the schedule OUTPUT: SQ.event_schedule\n",
      "when exactly is it officially the event scheduled <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "what importance where is the usual precise flow of events OUTPUT: SQ.event_schedule\n",
      "but when is the international conference <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "their usual event itinerary <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "will first we get the stickers for please answering commonly OUTPUT: SQ.event_prize\n",
      "4 or how very many speakers <PERIOD> <PERIOD> <PERIOD> will OUTPUT: SQ.event_speakers\n",
      "what's next to the outstanding prize box money <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "where can i just see on here the event schedule OUTPUT: SQ.event_schedule\n",
      "what but when is this event <QUESTION_MARK> to do everything OUTPUT: SQ.event_date\n",
      "whatas the new construction schedule <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "when i would that i be provided additional building accommodation OUTPUT: FAQ.accom\n",
      "when nowhere else are the normal events happening <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "how infinitely instead many possible days of the event would OUTPUT: SQ.event_schedule\n",
      "explain what will decide the winner get OUTPUT: SQ.event_prize\n",
      "since when who is the event <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "<PERIOD> <PERIOD> <PERIOD> what exactly is of this upcoming event OUTPUT: SQ.event_details\n",
      "what precisely is now the deadline for web account registration OUTPUT: SQ.reg_lastdate\n",
      "in what are also the dates typical of performing the OUTPUT: SQ.event_date\n",
      "what's the real great society event <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "who are the keynote speakers today included today in this OUTPUT: SQ.event_speakers\n",
      "and when it is the event organised OUTPUT: SQ.event_date\n",
      "and what work is with the cash prize <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "since but when will that event will really take place OUTPUT: SQ.event_date\n",
      "whom could award <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "so which fields are supposedly being fully covered <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "when just when is this the appropriate event <QUESTION_MARK> can OUTPUT: SQ.event_schedule\n",
      "exactly what information is this this event about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "for now who truly will be the speaker <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "and when and here is the first event being hosted OUTPUT: SQ.event_schedule\n",
      "what is the event there we all constantly fuss about OUTPUT: SQ.event_details\n",
      "what does exist is the detailed event release schedule OUTPUT: SQ.event_schedule\n",
      "what bad news is this OUTPUT: SQ.event_details\n",
      "<PERIOD> <PERIOD> <PERIOD> then what is with the first itinerary OUTPUT: SQ.event_schedule\n",
      "holes in what is this <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "thus is internal accomadation available simply as for weak externals OUTPUT: FAQ.accom\n",
      "what is the tomorrow dance schedule <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "what time <PERIOD> <PERIOD> <PERIOD> is this about OUTPUT: SQ.event_details\n",
      "then will the accommodation costs costs be included again in OUTPUT: FAQ.accom\n",
      "and but what <PERIOD> <PERIOD> <PERIOD> about accomodation for taking OUTPUT: FAQ.accom\n",
      "how how quickly will you accommodate <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "and so how longer would the main event go on OUTPUT: SQ.event_schedule\n",
      "guess who exactly there is ever going to address the OUTPUT: SQ.event_speakers\n",
      "what bad do can i truly get if only i OUTPUT: SQ.event_prize\n",
      "complete concert schedule OUTPUT: SQ.event_schedule\n",
      "both who are also the speakers OUTPUT: SQ.event_speakers\n",
      "so when is when the event OUTPUT: SQ.event_date\n",
      "guess who we will be speaking at ten for the OUTPUT: SQ.event_speakers\n",
      "all who <PERIOD> <PERIOD> <PERIOD> are the main speakers <EXCLAMATION_MARK> OUTPUT: SQ.event_speakers\n",
      "is accommodation well enough provided <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "so what yet is the schedule OUTPUT: SQ.event_schedule\n",
      "who all will be coming right up to give first OUTPUT: SQ.event_speakers\n",
      "just when is such it going to really be getting OUTPUT: SQ.event_date\n",
      "who all are of the speakers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "what is this famous event truly about OUTPUT: SQ.event_details\n",
      "what about all the female trainers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "will <PERIOD> <PERIOD> <PERIOD> i get some more ridiculous bounty OUTPUT: SQ.event_prize\n",
      "when is it all gonna never start OUTPUT: SQ.event_schedule\n",
      "or the whatas the last deadline then for my college OUTPUT: SQ.reg_lastdate\n",
      "who really is coming to visit the student conference OUTPUT: SQ.event_speakers\n",
      "simply what are the expected rewards <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "what is making this awful whole event about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "so when to is it scheduled <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "see who someone is speaking OUTPUT: SQ.event_speakers\n",
      "so who was all farther along exactly are the speakers OUTPUT: SQ.event_speakers\n",
      "what makes right is this all all about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "but not until fourth when can i register <QUESTION_MARK> OUTPUT: SQ.reg_lastdate\n",
      "<PERIOD> <PERIOD> <PERIOD> how will getting the prize eventually be OUTPUT: SQ.event_prize\n",
      "so do we still have orders to also stay on OUTPUT: SQ.event_schedule\n",
      "so on what dates are for the events going today OUTPUT: SQ.event_date\n",
      "why because what are of the dates he set for OUTPUT: SQ.event_date\n",
      "how is everybody holding on it really different being just OUTPUT: SQ.event_date\n",
      "then what news can i get <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "prizes for the challenge book winners <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "but what is the tour your itinerary OUTPUT: SQ.event_schedule\n",
      "but how very long many days the actual event would OUTPUT: SQ.event_date\n",
      "precisely what city colour is the event about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "what'the lot s else is just the prize <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "where can am sure i stay OUTPUT: FAQ.accom\n",
      "can i <PERIOD> <PERIOD> <PERIOD> please see a list of OUTPUT: SQ.event_speakers\n",
      "who are the most current guests OUTPUT: SQ.event_speakers\n",
      "are we short there of second on points and third OUTPUT: SQ.event_prize\n",
      "do did we get lucky any more prizes <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "where can help myself i stay <QUESTION_MARK> OUTPUT: FAQ.accom\n",
      "but what is at the last appropriate date fixed for OUTPUT: SQ.reg_lastdate\n",
      "but when is last it being being held <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "they decide then what is the main prize for the OUTPUT: SQ.event_prize\n",
      "what good is the criteria employed for also getting into OUTPUT: SQ.reg_fee\n",
      "when time exists is the event happening OUTPUT: SQ.event_date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when is even even the same event going by to OUTPUT: SQ.event_date\n",
      "yet what is open the con <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "where will help we still get t - face shirts OUTPUT: SQ.event_prize\n",
      "do <PERIOD> <PERIOD> <PERIOD> you actually have any outstanding prizes OUTPUT: SQ.event_prize\n",
      "when of now is it OUTPUT: SQ.event_date\n",
      "only later can we then approach anyone for registration any OUTPUT: SQ.reg_lastdate\n",
      "it just what does it entail OUTPUT: SQ.event_details\n",
      "when of and where it is all was of it OUTPUT: SQ.event_date\n",
      "on what precisely those specified dates will the public sporting OUTPUT: SQ.event_date\n",
      "what is en vogue opencon <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "what good is timing of already winning the event OUTPUT: SQ.event_schedule\n",
      "what natural one would that be the proper last service OUTPUT: SQ.reg_lastdate\n",
      "could you please name the latest speakers from who now OUTPUT: SQ.event_speakers\n",
      "then till what proposed date can i apply you for OUTPUT: SQ.reg_lastdate\n",
      "now what is from all the event about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "what better date <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "when when is the last long day already starting to OUTPUT: SQ.reg_lastdate\n",
      "but till precisely which date can i ever register OUTPUT: SQ.reg_lastdate\n",
      "when is coming this extraordinary event <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "now what will i ever get if i ever can OUTPUT: SQ.event_prize\n",
      "if are we there cash prizes <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "can you remember i have read the whole usual itinerary OUTPUT: SQ.event_schedule\n",
      "will not this hidden speaker be back there <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "what reasons are there for the prizes being also offered OUTPUT: SQ.event_prize\n",
      "how is she putting the event to schedule <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "who will be taking the opening prayer after sessions OUTPUT: SQ.event_speakers\n",
      "but can we register on their designated spot <QUESTION_MARK> OUTPUT: SQ.reg_lastdate\n",
      "what exactly will we happen when <QUESTION_MARK> OUTPUT: SQ.event_schedule\n",
      "but what is the consolation prize and money <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "<PERIOD> <PERIOD> <PERIOD> what year is thus the competition schedule OUTPUT: SQ.event_schedule\n",
      "where and what exactly is open con OUTPUT: SQ.event_details\n",
      "do you kids have any speakers worth ever coming directly OUTPUT: SQ.event_speakers\n",
      "on other what different days now we have the actual OUTPUT: SQ.event_date\n",
      "so whatas so fucking great involved in hosting this particular OUTPUT: SQ.event_details\n",
      "when or is after this the last date <QUESTION_MARK> OUTPUT: SQ.reg_lastdate\n",
      "before then who would be presiding as only speakers wait OUTPUT: SQ.event_speakers\n",
      "what is just the time flow of processing the new OUTPUT: SQ.event_schedule\n",
      "will there always not be real goodies <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "what is just this all about <QUESTION_MARK> OUTPUT: SQ.event_details\n",
      "is stay longer provided always for us OUTPUT: FAQ.accom\n",
      "are there <PERIOD> <PERIOD> <PERIOD> any any potential prizes <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "and who all are of among the potential prospective speakers OUTPUT: SQ.event_speakers\n",
      "from what are only exactly those the dates for when OUTPUT: SQ.event_date\n",
      "what will ever mean we actually do in fact planning OUTPUT: SQ.event_details\n",
      "now who are now the speakers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "that general with info about seeing the speakers <QUESTION_MARK> OUTPUT: SQ.event_speakers\n",
      "does it beating the winner necessarily get a cash prize OUTPUT: SQ.event_prize\n",
      "in at least how frequently is the accomodation really done OUTPUT: FAQ.accom\n",
      "see just what is on this the last day scheduled OUTPUT: SQ.reg_lastdate\n",
      "last recorded date to attendance register OUTPUT: SQ.reg_lastdate\n",
      "what great benefits do we get hidden away than from OUTPUT: SQ.event_details\n",
      "when do we you first see need any my presence OUTPUT: SQ.event_date\n",
      "or what character is the breakdown method for winning all OUTPUT: SQ.event_prize\n",
      "only what there else really is the event all about OUTPUT: SQ.event_details\n",
      "just when else will opencon 1 be more held <QUESTION_MARK> OUTPUT: SQ.event_date\n",
      "who are the speakers for judging the first current event OUTPUT: SQ.event_speakers\n",
      "when exactly is tomorrow the last job date gone to OUTPUT: SQ.reg_lastdate\n",
      "and what needs is the itinerary track of your future OUTPUT: SQ.event_schedule\n",
      "now what exactly else is opencon basically good talking about OUTPUT: SQ.event_details\n",
      "what good cause is this event about OUTPUT: SQ.event_details\n",
      "oh so how much is now the prize money OUTPUT: SQ.event_prize\n",
      "who are named for the selected featured inspirational speakers for OUTPUT: SQ.event_speakers\n",
      "can we talk again over to his <PERIOD> <PERIOD> <PERIOD> OUTPUT: SQ.event_speakers\n",
      "but so now when is the list last for registration OUTPUT: SQ.reg_lastdate\n",
      "what about us paying back the price money <QUESTION_MARK> OUTPUT: SQ.event_prize\n",
      "Val Loss: 2.070140         Val_Acuuracy: 95.58011049723757\n"
     ]
    }
   ],
   "source": [
    "net_1.eval()\n",
    "val_h = net_1.init_hidden(batch_size)\n",
    "val_losses = []\n",
    "a=[]\n",
    "net_1.eval()\n",
    "for inputs, labels in valid_loader:\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                inputs=torch.tensor(inputs).to(torch.int64)\n",
    "                labels=torch.tensor(labels).to(torch.long)\n",
    "                \n",
    "        output, val_h = net_1(inputs, val_h)\n",
    "        _,index=torch.topk(output,1)\n",
    "        a.append(index.item()==labels.item())\n",
    "        val_loss = criterion(output, labels)\n",
    "        for i in inputs.squeeze():\n",
    "            if i:\n",
    "                print(int_to_words[i.item()],end=\" \")\n",
    "        print('OUTPUT:',int_to_ans[index.item()])\n",
    "                \n",
    "        \n",
    "        \n",
    "        val_losses.append(val_loss.item())\n",
    "print( \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\"        Val_Acuuracy:\",(a.count(1)/(a.count(0)+a.count(1)))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semantic_Classifier(\n",
       "  (embedding): Embedding(1411, 300)\n",
       "  (lstm): LSTM(300, 256, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=19, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_1.state_dict(),\"net_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
